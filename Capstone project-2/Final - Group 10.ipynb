{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7691acc1-6b2e-45bc-b274-b01bb9f15f4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## STEP 1. Join tables and filter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6a0b47b-09b9-4966-93e7-f8f069bff842",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1.1 Prepare necessary libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af0cb97e-eabf-4a87-a435-7763ab5709f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and functions\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, translate, trim, explode, regexp_replace, col, lower\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.sql.functions import col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8007556-b013-49c7-9c74-ee31ebafc60e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating Spark Session\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"ML Model\")\n",
    "         .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04fbf8f8-23c9-4058-a76a-a4d54abd17f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read in the tables\n",
    "\n",
    "posts = spark.read.parquet(\"/tmp/project/posts.parquet\")\n",
    "postType = spark.read.parquet(\"/tmp/project/PostType.parquet\")\n",
    "Users = spark.read.parquet(\"/tmp/project/user.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "765ee8b0-8d69-4139-b1c0-1909362bab82",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1.2 Join the tables Posts and postTypes by it post type id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9183d6b9-5407-4326-9b15-7a339a34bdbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# at this moment, we only use Posts and posttypes to train the model. so let's join them iwith the posttype id. \n",
    "\n",
    "df = posts.join(postType, posts.PostTypeId == postType.id)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1980350c-3318-4a83-ba7a-abf96af7a5e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1.3 Filter the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "045a1ba8-4b7b-4e0a-b277-1c0147831d58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In the posttypes table, there is a column called `Type` which indicates if the posts is a question or an answer. We only need the 'question' entires. For these 'Question' rows, we will run machine learning model on the join the 'Body' column of the 'Posts' table. To tell what topic this post is about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3595dcae-59a9-4f27-a0f3-403f33852d02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter the dataframe to only include questions\n",
    "df = df.filter(col(\"Type\") == \"Question\")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d13ac859-4a38-4563-83ba-77192c009c12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Formatting the 'Body' and `Tag` columns for machine learning training\n",
    "df = (df.withColumn('Body', regexp_replace(df.Body, r'<.*?>', '')) # Transforming HTML code to strings\n",
    "      .withColumn(\"Tags\", split(trim(translate(col(\"Tags\"), \"<>\", \" \")), \" \")) # Making a list of the tags\n",
    ")\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9e63353-6912-44c0-9090-93c24df2e8cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1.4 Create a checkpoint to save the dataframe to file only contain the `Body` and `Tag` we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2598210-6502-4f8d-8f3f-42aa0207ee2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.select(col(\"Body\").alias(\"text\"), col(\"Tags\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f76fc3e-bfd0-4352-9c19-261ff735932a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Producing the tags as individual tags instead of an array\n",
    "# This is duplicating the posts for each possible tag\n",
    "df = df.select(\"text\", explode(\"Tags\").alias(\"tags\"))\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4ccb4c1-e56e-432b-9932-a1cade9b85b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## STEP 2. Based on the above dataframe, prepare data from machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0f276e2-7e83-4ae8-9a0e-17c58081c225",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2.1. Text Cleaning Preprocessing\n",
    "\n",
    "`pyspark.sql.functions.regexp_replace` is used to process the text\n",
    "\n",
    "1. Remove URLs such as `http://stackoverflow.com`\n",
    "2. Remove special characters\n",
    "3. Substituting multiple spaces with single space\n",
    "4. Lowercase all text\n",
    "5. Trim the leading/trailing whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1fdcca2-24dc-4bb9-ad7a-aae2dfdbaff2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "df = df.withColumn('text', regexp_replace('text', r\"http\\S+\", \"\")) \\\n",
    "                    .withColumn('text', regexp_replace('text', r\"[^a-zA-z]\", \" \")) \\\n",
    "                    .withColumn('text', regexp_replace('text', r\"\\s+\", \" \")) \\\n",
    "                    .withColumn('text', lower('text')) \\\n",
    "                    .withColumn('text', trim('text')) \n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66d6fb27-d5f5-4277-8b68-13b308716f2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df =  df.withColumn(\"tags\", regexp_replace(\"tags\", r\"[^a-zA-z]\", \" \")) \\\n",
    "      .withColumn(\"tags\", regexp_replace(\"tags\", r\"\\s+\", \" \")) \\\n",
    "      .withColumn(\"tags\", lower(\"tags\")) \\\n",
    "      .withColumn(\"tags\", trim(\"tags\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1605204-829c-467b-98c3-78a3a6d6d579",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## STEP 3. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13f936b6-6403-4cb8-9792-e81e5de8e323",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.1 Data Prepration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c26ac309-6713-459c-9ef0-8288b3721540",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "# Step 1: Creating the joined table\n",
    "df = posts.join(postType, posts.PostTypeId == postType.id)\n",
    "# Step 2: Selecting only Question posts\n",
    "df = df.filter(col(\"Type\") == \"Question\")\n",
    "# Step 3: Formatting the raw data\n",
    "df = (df.withColumn('Body', regexp_replace(df.Body, r'<.*?>', ''))\n",
    "      .withColumn(\"Tags\", split(trim(translate(col(\"Tags\"), \"<>\", \" \")), \" \"))\n",
    ")\n",
    "# Step 4: Selecting the columns\n",
    "df = df.select(col(\"Body\").alias(\"text\"), col(\"Tags\"))\n",
    "# Step 5: Getting the tags\n",
    "df = df.select(\"text\", explode(\"Tags\").alias(\"tags\"))\n",
    "\n",
    "df =  df.withColumn(\"tags\", regexp_replace(\"tags\", r\"[^a-zA-z]\", \" \")) \\\n",
    "      .withColumn(\"tags\", regexp_replace(\"tags\", r\"\\s+\", \" \")) \\\n",
    "      .withColumn(\"tags\", lower(\"tags\")) \\\n",
    "      .withColumn(\"tags\", trim(\"tags\"))  \n",
    "# Step 6: Clean the text\n",
    "df = df.withColumn('text', regexp_replace('text', r\"http\\S+\", \"\")) \\\n",
    "                    .withColumn('text', regexp_replace('text', r\"[^a-zA-z]\", \" \")) \\\n",
    "                    .withColumn('text', regexp_replace('text', r\"\\s+\", \" \")) \\\n",
    "                    .withColumn('text', lower('text')) \\\n",
    "                    .withColumn('text', trim('text')) \n",
    "# Step 7: Initializing the transfomers\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "stopword_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"filtered\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5)\n",
    "label_encoder = StringIndexer(inputCol = \"tags\", outputCol = \"label\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a941d8e-1135-4073-acfa-34a281836efe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.2 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84b2a6a5-688d-45fb-b4f7-816fc72bee04",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Model 1: Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9970f62-2da9-4c5f-aeec-d68ff6b8fba0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "# Step 1: Train Test Split\n",
    "train, test = df.randomSplit([0.9, 0.1], seed=20200819)\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "# Step 3: Creating the pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopword_remover, cv, idf, label_encoder, lr])\n",
    "# Step 4: Fitting and transforming (predicting) using the pipeline\n",
    "pipeline_model = pipeline.fit(train)\n",
    "predictions = pipeline_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a49b154-57b2-4bf3-a9be-6a6176c6829f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.3665\nROC-AUC: 0.3386\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "roc_auc2 = evaluator.evaluate(predictions)\n",
    "accuracy2 = predictions.filter(predictions.label == predictions.prediction).count() / float(predictions.count())\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy2))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "693fddbc-e72d-4aeb-a9d6-790a4c0e7e83",
     "showTitle": true,
     "title": ""
    }
   },
   "source": [
    "#### Model 2: Logistic Regression for classes greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2649725-1563-4f76-8114-5c8eba8a6b1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#WORK\n",
    "from pyspark.sql.functions import col\n",
    "# Get the count of each class\n",
    "class_counts = df.groupBy(\"tags\").count()\n",
    "# Filter the class_counts dataframe to keep only rows where count > 1\n",
    "filtered_counts = class_counts.filter(col(\"count\") > 1)\n",
    "# Join the original dataframe with the filtered_counts dataframe\n",
    "filtered_df = df.join(filtered_counts, \"tags\", \"left\")\n",
    "# Drop the rows where count value = 1\n",
    "filtered_df = filtered_df.filter(col(\"count\").isNotNull())\n",
    "filtered_counts = filtered_df.filter(col(\"count\") > 1)\n",
    "\n",
    "# Machine Learning\n",
    "# Step 1: Train Test Split\n",
    "train, test = filtered_counts.randomSplit([0.9, 0.1], seed=20200819)\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "\n",
    "# Step 3: Creating the pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopword_remover, cv, idf, label_encoder, lr])\n",
    "\n",
    "# Step 4: Fitting and transforming (predicting) using the pipeline\n",
    "pipeline_model = pipeline.fit(train)\n",
    "predictions = pipeline_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8bc4572-170c-4824-b13a-b463fc1969db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.4634\nROC-AUC: 0.4427\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "roc_auc2 = evaluator.evaluate(predictions)\n",
    "accuracy2 = predictions.filter(predictions.label == predictions.prediction).count() / float(predictions.count())\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy2))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d68ef08-3d3b-45cf-a1a0-39e4c8f81242",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Model 3: NaiveBayes for classes greater than 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b202531f-b494-4bec-a731-0f206b3a8b4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#WORK\n",
    "# Get the count of each class\n",
    "class_counts = df.groupBy(\"tags\").count()\n",
    "# Filter the class_counts dataframe to keep only rows where count > 1\n",
    "filtered_counts = class_counts.filter(col(\"count\") > 1)\n",
    "# Join the original dataframe with the filtered_counts dataframe\n",
    "filtered_df = df.join(filtered_counts, \"tags\", \"left\")\n",
    "# Drop the rows where count value = 1\n",
    "filtered_df = filtered_df.filter(col(\"count\").isNotNull())\n",
    "filtered_counts = filtered_df.filter(col(\"count\") > 1)\n",
    "\n",
    "# Machine Learning\n",
    "# Step 1: Train Test Split\n",
    "train, test = filtered_counts.randomSplit([0.9, 0.1], seed=20200819)\n",
    "\n",
    "# Step 3: Creating the pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopword_remover, cv, idf, label_encoder, nb])\n",
    "\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# Step 4: Fitting and transforming (predicting) using the pipeline\n",
    "pipeline_model = pipeline.fit(train)\n",
    "predictions = pipeline_model.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e003f450-b32b-4ad0-bce6-e7357c67cc35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.4744\nROC-AUC: 0.4957\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "roc_auc2 = evaluator.evaluate(predictions)\n",
    "accuracy2 = predictions.filter(predictions.label == predictions.prediction).count() / float(predictions.count())\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy2))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1af18598-3fbd-44f3-8992-bb4c9f850c29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Model 4: Logisitic Regression for top 20 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3c75028-925a-4c6f-b966-58b2dede372a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the count of each class\n",
    "class_counts_for1 = df.groupBy(\"tags\").count()\n",
    "\n",
    "# Filter the class_counts dataframe to keep only rows where count > 1\n",
    "filtered_counts = class_counts_for1.filter(col(\"count\") > 1)\n",
    "filtered_df.display()\n",
    "\n",
    "# # Join the original dataframe with the filtered_counts dataframe\n",
    "# filtered_df = df.join(filtered_counts, \"tags\", \"left\")\n",
    "\n",
    "# # Drop the rows where count value = 1\n",
    "# filtered_df = filtered_df.filter(col(\"count\").isNotNull())\n",
    "\n",
    "# # Display the filtered dataframe\n",
    "# filtered_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4b45300-2bd5-4f80-a967-d8bc49489503",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>tags</th></tr></thead><tbody><tr><td>c</td></tr><tr><td>java</td></tr><tr><td>javascript</td></tr><tr><td>jquery</td></tr><tr><td>php</td></tr><tr><td>android</td></tr><tr><td>iphone</td></tr><tr><td>net</td></tr><tr><td>objective c</td></tr><tr><td>mysql</td></tr><tr><td>html</td></tr><tr><td>python</td></tr><tr><td>sql server</td></tr><tr><td>asp net</td></tr><tr><td>ruby on rails</td></tr><tr><td>ios</td></tr><tr><td>sql</td></tr><tr><td>css</td></tr><tr><td>wpf</td></tr><tr><td>asp net mvc</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "c"
        ],
        [
         "java"
        ],
        [
         "javascript"
        ],
        [
         "jquery"
        ],
        [
         "php"
        ],
        [
         "android"
        ],
        [
         "iphone"
        ],
        [
         "net"
        ],
        [
         "objective c"
        ],
        [
         "mysql"
        ],
        [
         "html"
        ],
        [
         "python"
        ],
        [
         "sql server"
        ],
        [
         "asp net"
        ],
        [
         "ruby on rails"
        ],
        [
         "ios"
        ],
        [
         "sql"
        ],
        [
         "css"
        ],
        [
         "wpf"
        ],
        [
         "asp net mvc"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "tags",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the count of each class\n",
    "class_counts1 = df.groupBy(\"tags\").count()\n",
    "\n",
    "# Order the classes based on count in descending order\n",
    "top_20_tags = class_counts1.orderBy(col(\"count\").desc()).limit(20)\n",
    "\n",
    "# Print the order of the tags\n",
    "top_20_tags.select(\"tags\").display()\n",
    "# top_20_tags = ordered_classes.show(20)\n",
    "# top_20_tags.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3863973-f1cd-4f43-aedb-a6986255f0b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join the original dataframe with the filtered_counts dataframe\n",
    "filtered_df = df.join(top_20_tags, \"tags\", \"left\")\n",
    "\n",
    "# Drop the rows where count value = 1\n",
    "filtered_df = filtered_df.filter(col(\"count\").isNotNull())\n",
    "\n",
    "# Display the filtered dataframe\n",
    "filtered_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d8455b9-e5b4-475d-b145-6dcd421a9e11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8065\nROC-AUC: 0.8077\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning\n",
    "# Step 1: Train Test Split\n",
    "train, test = filtered_df.randomSplit([0.8, 0.2], seed=20200819)\n",
    "# Step 2: Initializing the transfomers\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "stopword_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"filtered\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5)\n",
    "label_encoder = StringIndexer(inputCol = \"tags\", outputCol = \"label\")\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "# Step 3: Creating the pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopword_remover, cv, idf, label_encoder, lr])\n",
    "# Step 4: Fitting and transforming (predicting) using the pipeline\n",
    "pipeline_model = pipeline.fit(train)\n",
    "predictions = pipeline_model.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "roc_auc2 = evaluator.evaluate(predictions)\n",
    "accuracy2 = predictions.filter(predictions.label == predictions.prediction).count() / float(predictions.count())\n",
    "\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy2))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7aec3639-cb84-406c-b11a-0daea1abb77d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Model 5: NaiveBayes for top 20 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9b0ad99-6cc4-4982-b276-e087e5492c20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7903\nROC-AUC: 0.7927\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Train Test Split\n",
    "train, test = filtered_df.randomSplit([0.8, 0.2], seed=20200819)\n",
    "# Step 2: Initializing the transfomers\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "stopword_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"filtered\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5)\n",
    "label_encoder = StringIndexer(inputCol = \"tags\", outputCol = \"label\")\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "# Step 3: Creating the pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopword_remover, cv, idf, label_encoder, nb])\n",
    "# Step 4: Fitting and transforming (predicting) using the pipeline\n",
    "pipeline_model_nb = pipeline.fit(train)\n",
    "predictions_nb = pipeline_model_nb.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "roc_auc_nb= evaluator.evaluate(predictions_nb)\n",
    "accuracy_nb = predictions_nb.filter(predictions_nb.label == predictions_nb.prediction).count() / float(predictions_nb.count())\n",
    "\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy_nb))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fd95738-e28b-4515-a32b-c42e3e08c825",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Model 6: Logisitic Regression for top 10 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c76eca1e-9662-4434-99ba-a00e0b2f9af9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>tags</th></tr></thead><tbody><tr><td>c</td></tr><tr><td>java</td></tr><tr><td>javascript</td></tr><tr><td>jquery</td></tr><tr><td>php</td></tr><tr><td>android</td></tr><tr><td>iphone</td></tr><tr><td>net</td></tr><tr><td>objective c</td></tr><tr><td>html</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "c"
        ],
        [
         "java"
        ],
        [
         "javascript"
        ],
        [
         "jquery"
        ],
        [
         "php"
        ],
        [
         "android"
        ],
        [
         "iphone"
        ],
        [
         "net"
        ],
        [
         "objective c"
        ],
        [
         "html"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "tags",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the count of each class\n",
    "class_counts1 = df.groupBy(\"tags\").count()\n",
    "\n",
    "# Order the classes based on count in descending order\n",
    "top_10_tags = class_counts1.orderBy(col(\"count\").desc()).limit(10)\n",
    "\n",
    "# Print the order of the tags\n",
    "top_10_tags.select(\"tags\").display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4636155-b946-4628-9b2c-374d35dc85fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join the original dataframe with the filtered_counts dataframe\n",
    "filtered_df_10 = df.join(top_10_tags, \"tags\", \"left\")\n",
    "\n",
    "# Drop the rows where count value = 1\n",
    "filtered_df_10 = filtered_df_10.filter(col(\"count\").isNotNull())\n",
    "\n",
    "# Display the filtered dataframe\n",
    "filtered_df_10.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd2a13cb-2506-40b4-ae0a-486ee6807363",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8000\nROC-AUC: 0.7999\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning\n",
    "# Step 1: Train Test Split\n",
    "train, test = filtered_df_10.randomSplit([0.9, 0.1], seed=20200819)\n",
    "# Step 2: Initializing the transfomers\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "stopword_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"filtered\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5)\n",
    "label_encoder = StringIndexer(inputCol = \"tags\", outputCol = \"label\")\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "# Step 3: Creating the pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopword_remover, cv, idf, label_encoder, lr])\n",
    "# Step 4: Fitting and transforming (predicting) using the pipeline\n",
    "pipeline_model = pipeline.fit(train)\n",
    "predictions = pipeline_model.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "roc_auc2 = evaluator.evaluate(predictions)\n",
    "accuracy2 = predictions.filter(predictions.label == predictions.prediction).count() / float(predictions.count())\n",
    "\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy2))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7add4f96-5d73-41b5-ad95-a3338d345d02",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Model 7: NaiveBayes for top 10 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42d4aa0c-b78c-48a3-bc83-8b5b45edd0ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7231\nROC-AUC: 0.7046\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Train Test Split\n",
    "train, test = filtered_df_10.randomSplit([0.9, 0.1], seed=20200819)\n",
    "# Step 2: Initializing the transfomers\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "stopword_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"filtered\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5)\n",
    "label_encoder = StringIndexer(inputCol = \"tags\", outputCol = \"label\")\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "# Step 3: Creating the pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopword_remover, cv, idf, label_encoder, nb])\n",
    "# Step 4: Fitting and transforming (predicting) using the pipeline\n",
    "pipeline_model_nb = pipeline.fit(train)\n",
    "predictions_nb = pipeline_model_nb.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "roc_auc_nb= evaluator.evaluate(predictions_nb)\n",
    "accuracy_nb = predictions_nb.filter(predictions_nb.label == predictions_nb.prediction).count() / float(predictions_nb.count())\n",
    "\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy_nb))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc_nb))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Final",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
